# === END SYNOPSIS HEADER ===
# === END SYNOPSIS HEADER ===
# === END SYNOPSIS HEADER ===
# === END SYNOPSIS HEADER ===
"""
Behavioral Analysis Module - Advanced code behavior detection.

This module contains specialized analysis for detecting complex behavioral
patterns in Python code, including state machines, call hierarchies,
and UI threading dependencies.
"""

import ast
from typing import Dict, List, Set, Tuple, Optional
from collections import defaultdict


class BehavioralAnalyzer:
    """
    Specialized analyzer for detecting behavioral patterns in code.
    
    This class focuses on advanced behavioral analysis including state machines,
    call hierarchies, threading patterns, and UI dependencies.
    """
    
    def __init__(self, analyzer, state=None):
        """Initialize with reference to main analyzer and optional shared state."""
        self.analyzer = analyzer
        # Use shared state if provided, otherwise use analyzer's state
        if state is not None:
            self.state = state
        else:
            self.state = getattr(analyzer, 'state', None)
    
    def render_call_hierarchy(self, max_depth: int = 3, max_children: int = 8) -> List[str]:
        """Render a depth-limited call hierarchy."""
        lines: List[str] = ["#", "# FUNCTION CALL HIERARCHY (depth-limited):", "#"]

        def dfs(node: str, depth: int, path: Tuple[str, ...]):
            if depth > max_depth:
                return
            indent = '  ' * depth
            lines.append(f"# {indent}- {node}()")
            children = sorted(self.analyzer.call_graph.get(node, []), 
                            key=lambda n: self.analyzer.functions.get(n, {'line': 0})['line'])
            if len(children) > max_children:
                children = children[:max_children]
                lines.append(f"# {indent}  ... +more")
            for ch in children:
                if ch in path:  # cycle guard
                    lines.append(f"# {indent}  - {ch}()  (cycle)")
                    continue
                dfs(ch, depth + 1, path + (ch,))

        for root in self.analyzer.call_roots[:30]:
            dfs(root, 0, (root,))
            lines.append("#")
        return lines

    def render_state_machines(self) -> List[str]:
        """Render detected state machines with enhanced detection."""
        # Use the enhanced detector if available
        if hasattr(self.analyzer, 'state_machine_detector') and self.analyzer.state_machine_detector:
            try:
                return self.analyzer.state_machine_detector.render_summary()
            except Exception:
                # Fallback to old implementation if enhanced rendering fails
                pass
        
        # Fallback to old implementation
        if not self.analyzer.state_vars:
            return []
        
        lines = ["#", "# STATE MACHINES (heuristic):", "#"]
        for var, meta in sorted(self.analyzer.state_vars.items()):
            vals = sorted(list(meta['values'] | self.analyzer.state_comparisons.get(var, set())))
            writers = ', '.join(sorted(list(meta['writers']))[:6])
            readers = ', '.join(sorted(list(meta['readers']))[:6])
            trans = ' â†’ '.join(vals) if len(vals) >= 2 else ', '.join(vals)
            lines.append(f"#   {var}: {trans if trans else '(values unknown)'}")
            if writers:
                lines.append(f"#     Set by: {writers}")
            if readers:
                lines.append(f"#     Checked by: {readers}")
        lines.append("#")
        return lines

    def render_ui_after_usage(self) -> List[str]:
        """Render UI threading dependencies."""
        if not self.analyzer.ui_after_users:
            return []
        lines = ["#", "# UI/THREADING DEPENDENCIES (tk.after usage):", "#"]
        for f in sorted(self.analyzer.ui_after_users, 
                       key=lambda n: self.analyzer.functions[n]['line']):
            lines.append(f"#   - {f}() calls .after(...) â†’ keep on main/UI thread or marshal via queue")
        lines.append("#")
        return lines

    def build_machine_block(self) -> List[str]:
        """Build the machine-readable data block."""
        from datetime import datetime
        ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        state_keys = ','.join(sorted(self.analyzer.state_vars.keys()))
        call_roots = ','.join(self.analyzer.call_roots[:30])
        init_seq = '; '.join(self.analyzer.init_sequence[:20])
        lines = [
            "# " + "\u2550" * 20,
            "# BEGIN MACHINE-READABLE DATA (for automated processing)",
            "# " + "\u2550" * 20,
            f"# SYNOPSIS_ANNOTATED: YES",
            f"# LAST_ANALYZED: {ts}",
            f"# FILE: {self.analyzer.filename}",
            f"# IMPORTS_EXTERNAL: {', '.join(sorted(x for x in self.analyzer.imports_external if x))}",
            f"# IMPORTS_LOCAL: {', '.join(sorted(x for x in self.analyzer.imports_local if x))}",
            f"# GLOBALS: {', '.join(sorted(self.analyzer.globals_found))}",
            f"# FUNCTIONS: {', '.join(sorted(self.analyzer.functions.keys()))}",
            f"# RETURNS: {', '.join(sorted([f for f, d in self.analyzer.functions.items() if d.get('returns_value')]))}",
            f"# THREAD_TARGETS: {', '.join(sorted(self.analyzer.threads_found))}",
            f"# HOTKEYS: {', '.join([hk for hk, _ in self.analyzer.hotkeys_found])}",
            f"# TK_BINDS: {', '.join([ev for ev, _ in self.analyzer.hotkeys_tkbind])}",
            f"# COMMAND_BINDS: {', '.join([cb for _, cb in self.analyzer.hotkeys_command_bind])}",
            f"# CLASSES: {', '.join(sorted(self.analyzer.classes.keys()))}",
            f"# IO_READS: {', '.join(sorted(self.analyzer.io_reads))}",
            f"# IO_WRITES: {', '.join(sorted(self.analyzer.io_writes))}",
            f"# CALLGRAPH_ROOTS: {call_roots}",
            f"# STATE_VARS: {state_keys}",
        ]
        
        # Optional enhancement - add state machine data
        if hasattr(self.analyzer, 'state_machine_results') and self.analyzer.state_machine_results:
            results = self.analyzer.state_machine_results
            num_machines = len(results.get('state_machines', []))
            num_transitions = len(results.get('transitions', []))
            lines.append(f"# STATE_MACHINES_COUNT: {num_machines}")
            lines.append(f"# STATE_TRANSITIONS_COUNT: {num_transitions}")
        
        lines.extend([
            f"# INIT_SEQUENCE: {init_seq}",
            "# END MACHINE-READABLE DATA",
            "# " + "\u2550" * 20,
        ])
        return lines

    def categorize_shared_state(self) -> List[Tuple[str, List[str]]]:
        """Categorize global variables by their likely purpose."""
        globs = sorted(self.analyzer.globals_found)
        if not globs:
            return []
        cats = {
            "UI State": [g for g in globs if any(s in g.lower() for s in ("ui", "window", "dialog", "label", "overlay", "widget", "root", "canvas"))],
            "Control State": [g for g in globs if any(s in g.lower() for s in ("mode", "pause", "run", "state", "enabled", "flag", "active", "status"))],
            "Timing State": [g for g in globs if any(s in g.lower() for s in ("time", "cooldown", "start", "end", "elapsed", "duration", "deadline", "timeout"))],
            "Position State": [g for g in globs if any(s in g.lower() for s in ("pos", "position", "x", "y", "drag", "cursor", "mouse", "offset"))],
            "Config State": [g for g in globs if any(s in g for s in ("CONFIG", "SETTINGS", "OPTION", "THRESHOLD", "DEFAULT", "PATH", "FILE")) or any(s in g.lower() for s in ("config", "setting", "threshold", "path", "file"))],
        }
        return [(k, v) for k, v in cats.items() if v]

    def group_modules_generic(self) -> Dict[str, List[str]]:
        """Group functions into logical modules for refactoring suggestions."""
        fnames = list(self.analyzer.functions.keys())
        buckets = {
            "config_manager.py": [],
            "io_files.py": [],
            "concurrency.py": [],
            "ui_layer.py": [],
            "networking.py": [],
            "cli_interface.py": [],
            "core_logic.py": [],
            "utilities.py": [],
        }
        for f in fnames:
            lname = f.lower()
            assigned = False
            if any(k in lname for k in ("config", "setting", "load_config", "save_config")):
                buckets["config_manager.py"].append(f); assigned = True
            if not assigned and any(k in lname for k in ("read", "write", "save", "load", "open", "export", "import", "serialize", "deserialize")):
                buckets["io_files.py"].append(f); assigned = True
            if not assigned and any(k in lname for k in ("thread", "lock", "mutex", "queue", "worker", "producer", "consumer", "async", "await", "pool")):
                buckets["concurrency.py"].append(f); assigned = True
            if not assigned and any(k in lname for k in ("ui", "gui", "window", "dialog", "overlay", "widget", "label", "button", "canvas")):
                buckets["ui_layer.py"].append(f); assigned = True
            if not assigned and any(k in lname for k in ("http", "https", "socket", "request", "response", "server", "client", "api", "fetch", "post", "get")):
                buckets["networking.py"].append(f); assigned = True
            if not assigned and any(k in lname for k in ("main", "entry", "arg", "argv", "cli", "parse_args")):
                buckets["cli_interface.py"].append(f); assigned = True
            if not assigned and any(k in lname for k in ("util", "helper", "common", "format", "parse", "validate", "calc", "compute")):
                buckets["utilities.py"].append(f); assigned = True
            if not assigned:
                buckets["core_logic.py"].append(f)
        return {k: v for k, v in buckets.items() if v}

    def analyze_high_priority_functions(self) -> List[Tuple[str, Dict, Set[str], Set[str]]]:
        """Identify functions that modify multiple globals or are thread targets."""
        high_priority = []
        for func_name, func_data in self.analyzer.functions.items():
            gw = func_data['writes'] & self.analyzer.globals_found
            gr = func_data['reads'] & self.analyzer.globals_found
            if len(gw) > 2 or (len(gw) > 0 and func_name in self.analyzer.threads_found):
                high_priority.append((func_name, func_data, gr, gw))
        return sorted(high_priority, key=lambda it: it[1]['line'])

    def analyze_function_dependencies(self) -> List[Tuple[str, List[str]]]:
        """Analyze functions with high fan-out (calling many other functions)."""
        fanout = {f: [c for c in cs if c in self.analyzer.functions] 
                 for f, cs in self.analyzer.call_graph.items()}
        critical = [(f, cs) for f, cs in fanout.items() if len(cs) > 3]
        return sorted(critical, key=lambda x: len(x[1]), reverse=True)

    def generate_behavioral_summary(self) -> List[str]:
        """Generate a comprehensive behavioral analysis summary."""
        lines = []
        
        # Function Call Hierarchy
        lines.extend(self.render_call_hierarchy(max_depth=3, max_children=8))
        lines.append("#" + "=" * 79)

        # State Machines
        sm = self.render_state_machines()
        if sm:
            lines.extend(sm)
            lines.append("#" + "=" * 79)

        # UI/Threading dependencies
        ui_after = self.render_ui_after_usage()
        if ui_after:
            lines.extend(ui_after)
            lines.append("#" + "=" * 79)

        # Initialization Sequence
        if self.analyzer.init_sequence:
            lines.extend(["#", "# \U0001F680 INITIALIZATION SEQUENCE:", "#"])  # ğŸš€
            for i, step in enumerate(self.analyzer.init_sequence[:20], 1):
                lines.append(f"#   {i}. {step}")
            if len(self.analyzer.init_sequence) > 20:
                lines.append(f"#   ... +{len(self.analyzer.init_sequence)-20} more")
            lines.append("#" + "=" * 79)

        return lines
